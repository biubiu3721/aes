{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7800c9d-7ac1-400f-a69b-d5c80edb8eaa",
   "metadata": {},
   "source": [
    "### env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da13774c-c69f-48cd-95dd-05daebb68607",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c52488-89dc-414a-a9aa-059a91a1bb6d",
   "metadata": {},
   "source": [
    "### libary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e656953-6a2c-4c66-98eb-52c3c2203141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "from torch.cuda import amp\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoConfig, TrainingArguments\n",
    "from transformers import AutoModelForTokenClassification, DataCollatorWithPadding, set_seed\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "from dataclasses import dataclass, field\n",
    "from torch.utils.data import DataLoader\n",
    "from accelerate import Accelerator, DistributedType\n",
    "from tqdm import tqdm\n",
    "from timm.utils import ModelEmaV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21017acb-779e-436e-8d3c-f5ff6f39cd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from adversarial_training import AWP, FGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7353a1b0-0c36-4ee6-910d-c063a4d76591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from utils import create_scheduler, create_custom_deberta_optimizer\n",
    "from metrics import compute_metrics\n",
    "from models import AESModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5d80c1-134a-430c-9ec0-22a9e87d697b",
   "metadata": {},
   "source": [
    "### params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a130c437-611e-432a-baef-b37c5be984e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0 # 2.948\n",
    "b = 1.092\n",
    "data_path = '../datasets/train.csv'\n",
    "exp_name = 'exp5'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "use_amp = True\n",
    "TRAINING_MODEL_PATH = 'microsoft/deberta-v3-base'  # 'h2oai/h2o-danube-1.8b-base' #\"microsoft/deberta-v3-base\"  # your model path\n",
    "batch_size = 16\n",
    "epoches = 5\n",
    "lr = 10e-5\n",
    "head_lr = 1e-4\n",
    "if_awp = False\n",
    "if_fgm = False\n",
    "max_grad_norm = 1000\n",
    "gradient_accumulation_steps = 1\n",
    "discriminative_learning_rate = True\n",
    "discriminative_learning_rate_num_groups = 12\n",
    "discriminative_learning_rate_decay_rate = 0.99\n",
    "ema_decay = 0.99\n",
    "TRAINING_MAX_LENGTH = 1280  # I use 1280 locally\n",
    "save_name = TRAINING_MODEL_PATH.replace('/', '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cabd84c-2381-41fb-98fc-86484fe1b145",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da8e5f40-6550-49b7-a0a0-7f2e680c82d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path)\n",
    "data[\"fold\"] = -1\n",
    "X = data[\"full_text\"]\n",
    "y = data[\"score\"]\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for i, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
    "    data.loc[val_index, \"fold\"] = i\n",
    "data['score'] = data['score'] - a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd65c59f-8242-48e0-9d8c-f3a190bab37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      essay_id                                          full_text  score  fold\n",
      "0      000d118  Many people have car where they live. The thin...      3     0\n",
      "1      000fe60  I am a scientist at NASA that is discussing th...      3     0\n",
      "2      001ab80  People always wish they had the same technolog...      4     0\n",
      "3      001bdc0  We all heard about Venus, the planet without a...      4     0\n",
      "4      002ba53  Dear, State Senator\\n\\nThis is a letter to arg...      3     0\n",
      "...        ...                                                ...    ...   ...\n",
      "17302  ffd378d  the story \" The Challenge of Exploing Venus \" ...      2     4\n",
      "17303  ffddf1f  Technology has changed a lot of ways that we l...      4     4\n",
      "17304  fff016d  If you don't like sitting around all day than ...      2     4\n",
      "17305  fffb49b  In \"The Challenge of Exporing Venus,\" the auth...      1     4\n",
      "17306  fffed3e  Venus is worthy place to study but dangerous. ...      2     4\n",
      "\n",
      "[17307 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "857635e0-e2a9-4b85-8d21-6e5efac4c116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be20e964-370e-400b-9480-1dac2559e8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(TRAINING_MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "453a5e22-7f60-4ada-8951-e30fe433cfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AESTrainingArguments(TrainingArguments):\n",
    "    adverserial_training: bool = field(default=False,\n",
    "                                       metadata={\"help\": \"Wheter to use adverserial_training or not to use.\"})\n",
    "    adverserial_method: str = field(default='AWP', metadata={\"help\": \"Specify the adverserial_method to use.\"})\n",
    "    adverserial_learning_rate: float = field(default=1e-3,\n",
    "                                             metadata={\"help\": \"Learning rate to use for adverserial training.\"})\n",
    "    adverserial_epsilon: float = field(default=1e-6, metadata={\"help\": \"Epsilon rate to use for adverserial training.\"})\n",
    "    adverserial_training_start_epoch: int = field(default=1, metadata={\"help\": \"Epoch to start adverserial training.\"})\n",
    "    discriminative_learning_rate: bool = field(default=False, metadata={\n",
    "        \"help\": \"Wheter to use discriminative_learning_rate or not to use.\"})\n",
    "    discriminative_learning_rate_num_groups: int = field(default=1, metadata={\n",
    "        \"help\": \"Number of groups for which we should use the same learning rate.\"})\n",
    "    discriminative_learning_rate_decay_rate: float = field(default=0.9, metadata={\n",
    "        \"help\": \"Exponential decay rate per layer to apply for discriminative learning rate.\"})\n",
    "    head_lr: float = field(default=1e-4, metadata={\n",
    "        \"help\": \"Learning rate to use for task specific head during args.discriminative_learning_rate==True.\"})\n",
    "    adam_optim_bits: int = field(default=None, metadata={\n",
    "        \"help\": \"Number of bits to use during optimization. Use 32 for standard Adam and 8 for 8-bit Adam. If None use Standard AdamW\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be7c4131-d29a-4ee8-9f86-d437536903f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(example, tokenizer):\n",
    "    tokenized = tokenizer(example['full_text'], return_offsets_mapping=True,\n",
    "                          truncation=True, max_length=TRAINING_MAX_LENGTH)\n",
    "\n",
    "    return {\n",
    "        **tokenized,\n",
    "        \"labels\": torch.tensor(example['score'], dtype=torch.float32),\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e119b68-0002-48f2-bccc-083153b41d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_one_epoch(model, val_dataloader):\n",
    "    model.eval()\n",
    "    val_labels = []\n",
    "    val_preds = []\n",
    "    for step, batch in tqdm(enumerate(val_dataloader), total=len(val_dataloader)):\n",
    "        # We could avoid this line since we set the accelerator with `device_placement=True`.\n",
    "        for key, value in batch.items():\n",
    "            batch[key] = value.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        if isinstance(outputs, tuple):\n",
    "            predictions = outputs[1]\n",
    "        else:\n",
    "            predictions = outputs.logits\n",
    "\n",
    "        val_preds.append(predictions.cpu().numpy())\n",
    "        val_labels.append(batch['labels'].cpu().numpy().reshape(-1,1))\n",
    "    val_logits = np.vstack(val_preds, ).reshape(-1)\n",
    "    val_gt = np.vstack(val_labels, ).reshape(-1)\n",
    "\n",
    "    y_true = val_gt + a\n",
    "    y_pred = (val_logits + a).clip(1, 6).round()\n",
    "    score = cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n",
    "\n",
    "    return score, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baee1f2d-a50c-4ee5-933e-3b2e2db7fd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_function(OUTPUT_DIR, args, fold):\n",
    "    config = AutoConfig.from_pretrained(TRAINING_MODEL_PATH)\n",
    "    config.max_position_embeddings = 2048\n",
    "    config.num_labels = 1\n",
    "    config.position_buckets = -1\n",
    "    # model = AutoModelForTokenClassification.from_pretrained(\n",
    "    #     TRAINING_MODEL_PATH,\n",
    "    #     config=config,\n",
    "    #     ignore_mismatched_sizes=True\n",
    "    # )\n",
    "\n",
    "    model = AESModel(TRAINING_MODEL_PATH)\n",
    "\n",
    "    collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    train_ds = Dataset.from_pandas(data[data['fold'] != fold])\n",
    "\n",
    "    train_ds = train_ds.map(tokenize, fn_kwargs={\"tokenizer\": tokenizer},\n",
    "                            num_proc=8).select_columns(['input_ids', 'attention_mask', 'token_type_ids', 'labels'])\n",
    "    train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True, collate_fn=collator)\n",
    "    val_ds = Dataset.from_pandas(data[data['fold'] == fold])\n",
    "    val_ds = val_ds.map(tokenize, fn_kwargs={\"tokenizer\": tokenizer, }, num_proc=8).select_columns(\n",
    "        ['input_ids', 'attention_mask', 'token_type_ids', 'labels'])\n",
    "    val_dataloader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, drop_last=False,\n",
    "                                collate_fn=collator)\n",
    "    set_seed(42)\n",
    "\n",
    "    model = model.to(device)\n",
    "    model_ema = ModelEmaV2(model, decay=ema_decay, device=None)\n",
    "    optimizer = create_custom_deberta_optimizer(args, model)\n",
    "    num_examples = len(train_ds)\n",
    "    num_update_steps_per_epoch = num_examples // (\n",
    "            batch_size * 4)\n",
    "    max_steps = args.max_steps if args.max_steps > 0 else math.ceil(\n",
    "        args.num_train_epochs * num_update_steps_per_epoch)\n",
    "    scheduler = create_scheduler(args, model, max_steps, optimizer)\n",
    "    best_score = 0\n",
    "    best_pred = None\n",
    "    if if_awp:\n",
    "        print('Enable AWP')\n",
    "        awp = AWP(model, optimizer, adv_lr=0.001, adv_eps=0.001)\n",
    "    if if_fgm:\n",
    "        print('Enable FGM')\n",
    "        fgm = FGM(model)\n",
    "    awp_start = 2\n",
    "    scaler = amp.GradScaler(enabled=use_amp)\n",
    "    for epoch in range(epoches):\n",
    "        model.train()\n",
    "\n",
    "        total_loss = 0\n",
    "\n",
    "        for step, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "            # We could avoid this line since we set the accelerator with `device_placement=True`.\n",
    "            for key, value in batch.items():\n",
    "                batch[key] = value.to(device)\n",
    "\n",
    "            if if_awp and epoch >= awp_start:\n",
    "                awp.perturb()\n",
    "            with amp.autocast(use_amp):\n",
    "                outputs = model(**batch)\n",
    "            if isinstance(outputs, tuple):\n",
    "                loss = outputs[0]\n",
    "            else:\n",
    "                loss = outputs.loss\n",
    "            loss = loss / gradient_accumulation_steps\n",
    "            # We keep track of the loss at each epoch\n",
    "            total_loss += loss.detach().float()\n",
    "            scaler.scale(loss).backward()\n",
    "            if if_awp:\n",
    "                awp.restore()\n",
    "            if if_fgm:\n",
    "                fgm.attack()  # 在embedding上添加对抗扰动\n",
    "                outputs = model(**batch)\n",
    "                if isinstance(outputs, tuple):\n",
    "                    loss_adv = outputs[0]\n",
    "                else:\n",
    "                    loss_adv = outputs.loss\n",
    "                scaler.scale(loss_adv).backward()  # 反向传播，并在正常的grad基础上，累加对抗训练的梯度\n",
    "                fgm.restore()\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            if (step + 1) % gradient_accumulation_steps == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "                model_ema.update(model)\n",
    "        score, y_pred = eval_one_epoch(model, val_dataloader)\n",
    "        if score > best_score:\n",
    "            torch.save(model.state_dict(), str(f\"./{OUTPUT_DIR}/best_model_fold{fold}.pth\"))\n",
    "            best_score = score\n",
    "            best_pred = y_pred\n",
    "        print(f'fold_{fold} current score is ********')\n",
    "        print(score)\n",
    "        print(f'fold_{fold} best score is ********')\n",
    "        print(best_score)\n",
    "    part_oof = data[data['fold'] == fold].copy().reset_index(drop=True)\n",
    "    part_oof['pred'] = best_pred\n",
    "    part_oof = part_oof[['essay_id', 'score', 'pred']]\n",
    "    return part_oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ec12350-64a2-47c4-ae03-2c5db8f5d939",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ConnectTimeout",
     "evalue": "HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /microsoft/deberta-v3-base/resolve/main/model.safetensors (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f6d78634bb0>, 'Connection to huggingface.co timed out. (connect timeout=10)'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/urllib3/connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/urllib3/util/connection.py:95\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgetaddrinfo returns an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 85\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sock\n",
      "\u001b[0;31mTimeoutError\u001b[0m: timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectTimeoutError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/urllib3/connectionpool.py:386\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/urllib3/connectionpool.py:1042\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[0;32m-> 1042\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/urllib3/connection.py:358\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;66;03m# Add certificate verification\u001b[39;00m\n\u001b[0;32m--> 358\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m     hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/urllib3/connection.py:179\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeoutError(\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m timed out. (connect timeout=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout),\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mConnectTimeoutError\u001b[0m: (<urllib3.connection.HTTPSConnection object at 0x7f6d78634bb0>, 'Connection to huggingface.co timed out. (connect timeout=10)')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m--> 787\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    790\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/urllib3/util/retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[0;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[1;32m    594\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /microsoft/deberta-v3-base/resolve/main/model.safetensors (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f6d78634bb0>, 'Connection to huggingface.co timed out. (connect timeout=10)'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectTimeout\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 37\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# val_ds = val_ds.class_encode_column(\"group\")\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     args \u001b[38;5;241m=\u001b[39m AESTrainingArguments(\n\u001b[1;32m      9\u001b[0m         output_dir\u001b[38;5;241m=\u001b[39mOUTPUT_DIR,\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;66;03m# fp16=True,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;66;03m# max_grad_norm=0.3\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     )\n\u001b[0;32m---> 37\u001b[0m     part_oof \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOUTPUT_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     res\u001b[38;5;241m.\u001b[39mappend(part_oof)\n\u001b[1;32m     40\u001b[0m oof \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(res)\n",
      "Cell \u001b[0;32mIn[16], line 12\u001b[0m, in \u001b[0;36mtrain_function\u001b[0;34m(OUTPUT_DIR, args, fold)\u001b[0m\n\u001b[1;32m      5\u001b[0m config\u001b[38;5;241m.\u001b[39mposition_buckets \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# model = AutoModelForTokenClassification.from_pretrained(\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#     TRAINING_MODEL_PATH,\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#     config=config,\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     ignore_mismatched_sizes=True\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAESModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTRAINING_MODEL_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m collator \u001b[38;5;241m=\u001b[39m DataCollatorWithPadding(tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n\u001b[1;32m     15\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_pandas(data[data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m fold])\n",
      "File \u001b[0;32m~/autodl-tmp/aes/aes-bert/models.py:33\u001b[0m, in \u001b[0;36mAESModel.__init__\u001b[0;34m(self, model_name, if_llm)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mattention_probs_dropout_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mhidden_size\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mif_llm \u001b[38;5;241m=\u001b[39m if_llm\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m if_llm:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:563\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    562\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/modeling_utils.py:3370\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3353\u001b[0m         has_file_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3354\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrevision\u001b[39m\u001b[38;5;124m\"\u001b[39m: revision,\n\u001b[1;32m   3355\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproxies\u001b[39m\u001b[38;5;124m\"\u001b[39m: proxies,\n\u001b[1;32m   3356\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m: token,\n\u001b[1;32m   3357\u001b[0m         }\n\u001b[1;32m   3358\u001b[0m         cached_file_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3359\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_dir,\n\u001b[1;32m   3360\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforce_download\u001b[39m\u001b[38;5;124m\"\u001b[39m: force_download,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3368\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhas_file_kwargs,\n\u001b[1;32m   3369\u001b[0m         }\n\u001b[0;32m-> 3370\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mhas_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_weights_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhas_file_kwargs\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   3371\u001b[0m             Thread(\n\u001b[1;32m   3372\u001b[0m                 target\u001b[38;5;241m=\u001b[39mauto_conversion,\n\u001b[1;32m   3373\u001b[0m                 args\u001b[38;5;241m=\u001b[39m(pretrained_model_name_or_path,),\n\u001b[1;32m   3374\u001b[0m                 kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore_errors_during_conversion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcached_file_kwargs},\n\u001b[1;32m   3375\u001b[0m                 name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThread-autoconversion\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3376\u001b[0m             )\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m   3377\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3378\u001b[0m     \u001b[38;5;66;03m# Otherwise, no PyTorch file was found, maybe there is a TF or Flax model file.\u001b[39;00m\n\u001b[1;32m   3379\u001b[0m     \u001b[38;5;66;03m# We try those to give a helpful error message.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/utils/hub.py:627\u001b[0m, in \u001b[0;36mhas_file\u001b[0;34m(path_or_repo, filename, revision, proxies, token, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    624\u001b[0m url \u001b[38;5;241m=\u001b[39m hf_hub_url(path_or_repo, filename\u001b[38;5;241m=\u001b[39mfilename, revision\u001b[38;5;241m=\u001b[39mrevision)\n\u001b[1;32m    625\u001b[0m headers \u001b[38;5;241m=\u001b[39m build_hf_headers(token\u001b[38;5;241m=\u001b[39mtoken, user_agent\u001b[38;5;241m=\u001b[39mhttp_user_agent())\n\u001b[0;32m--> 627\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     hf_raise_for_status(r)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/requests/api.py:100\u001b[0m, in \u001b[0;36mhead\u001b[0;34m(url, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a HEAD request.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhead\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/requests/adapters.py:507\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ConnectTimeoutError):\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, NewConnectionError):\n\u001b[0;32m--> 507\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ResponseError):\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RetryError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectTimeout\u001b[0m: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /microsoft/deberta-v3-base/resolve/main/model.safetensors (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f6d78634bb0>, 'Connection to huggingface.co timed out. (connect timeout=10)'))"
     ]
    }
   ],
   "source": [
    "\n",
    "res = []\n",
    "for fold in range(5):\n",
    "    OUTPUT_DIR = f'output_{save_name}_{exp_name}'  # your output path\n",
    "    if not os.path.exists(OUTPUT_DIR):\n",
    "        os.makedirs(OUTPUT_DIR)\n",
    "    # val_ds = val_ds.class_encode_column(\"group\")\n",
    "\n",
    "    args = AESTrainingArguments(\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        # fp16=True,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        # warmup_steps=100,\n",
    "        learning_rate=lr,\n",
    "        num_train_epochs=4,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=4,\n",
    "        report_to=\"none\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=1,\n",
    "        overwrite_output_dir=True,\n",
    "        load_best_model_at_end=True,\n",
    "        lr_scheduler_type='cosine',\n",
    "        metric_for_best_model=\"f1\",\n",
    "        greater_is_better=True,\n",
    "        #optim=\"adafactor\",\n",
    "        discriminative_learning_rate=discriminative_learning_rate,\n",
    "        discriminative_learning_rate_num_groups=discriminative_learning_rate_num_groups,\n",
    "        discriminative_learning_rate_decay_rate=discriminative_learning_rate_decay_rate,\n",
    "        head_lr=head_lr,\n",
    "        # deepspeed=\"ds_config_zero2.json\"\n",
    "        # gradient_checkpointing=True,\n",
    "        # weight_decay=0.001,\n",
    "        # max_grad_norm=0.3\n",
    "    )\n",
    "\n",
    "    part_oof = train_function(OUTPUT_DIR, args, fold)\n",
    "    res.append(part_oof)\n",
    "\n",
    "oof = pd.concat(res)\n",
    "oof['score'] = oof['score'] + a\n",
    "oof.to_csv(f'{OUTPUT_DIR}/oof.csv', index=None)\n",
    "\n",
    "y_true = oof['score']\n",
    "y_pred = oof['pred']\n",
    "total_score = cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n",
    "print(f'total cv is {total_score}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff964cc1-5ccd-413f-a376-dd7724a0f802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb319e8-525f-4ccb-836c-98ea42336983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684b8b93-f537-4711-9b6f-fe260055c0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
